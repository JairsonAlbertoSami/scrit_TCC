{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmwGm+JZVuvYrsTK3ZZ/jO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairsonAlbertoSami/scrit_TCC/blob/main/github_classificacao_artigo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Apresentação**\n",
        "Este Jupyter Notebook contém códigos e dados que foram discutidos no artigo."
      ],
      "metadata": {
        "id": "XLnEG0O7T8XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pdpbox\n",
        "!pip install lime\n",
        "!pip install shap\n",
        "!pip install eli5\n",
        "!pip install mlxtend\n",
        "!pip install interpret"
      ],
      "metadata": {
        "id": "iw6sdiuKshyI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "usje9qpLTtzb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import SelectPercentile, VarianceThreshold, SelectFromModel\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, Binarizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD, PCA\n",
        "from sklearn.metrics import (\n",
        "    make_scorer, accuracy_score, balanced_accuracy_score, average_precision_score, brier_score_loss, f1_score,\n",
        "    log_loss, precision_score, recall_score, jaccard_score, roc_auc_score, classification_report, confusion_matrix,\n",
        "    roc_curve, precision_recall_curve, auc,\n",
        ")\n",
        "from sklearn.utils import resample\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "from joblib import delayed, Parallel\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# montar drive do google\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEbfn7HzVC7u",
        "outputId": "51448273-341b-46d6-e579-355f8ab832c6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importar os dados em cvs"
      ],
      "metadata": {
        "id": "E2KbWD_YXvnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Data_TCC/df.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zKiYxQ9IVtDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapeamento = {\n",
        "    'agrocampes': \"Campestre\",\n",
        "    'praia': 'Áreas Descobertas',\n",
        "    'mangue': 'Mangue',\n",
        "    'areaUmida': 'Áreas Úmidas',\n",
        "    'vegetecaoD': 'Vegetação Densa'\n",
        "}\n",
        "\n",
        "# Renomear os valores na coluna 'classe' com base no dicionário de mapeamento\n",
        "df['classe'] = df['classe'].replace(mapeamento)"
      ],
      "metadata": {
        "id": "re7d6aQw5yHU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# O código a seguir filtra um DataFrame chamado 'df' para obter apenas as amostras que possuem valores válidos na coluna 'classe'.\n",
        "amostras = df[pd.isna(df['classe']) == False]\n",
        "amostras.head()\n"
      ],
      "metadata": {
        "id": "unRGWBM3VzYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera as principais estatísticas descritivas do DataFrame \"amostras\"\n",
        "amostras.describe()"
      ],
      "metadata": {
        "id": "cfqMOIqsXc4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de plotagem de dados faltantes (missing data) no DataFrame \"amostras\".\n",
        "# É uma ferramenta útil para identificar padrões de ausência de dados e auxiliar em tratamentos adequados.\n",
        "\n",
        "msno.matrix(amostras)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S0O7NCzla_E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A linha a seguir cria uma nova variável 'y', que é uma série contendo a coluna 'classe' do DataFrame 'amostras'.\n",
        "y = amostras['classe']\n",
        "\n",
        "# A linha abaixo cria um novo DataFrame 'X', que contém todas as colunas de 'amostras', exceto a coluna 'classe'.\n",
        "X = amostras.drop(columns=['classe'])\n"
      ],
      "metadata": {
        "id": "UN9hUiYHY9Mo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de barras das contagens de classes em 'y'.\n",
        "# Visualizar a distribuição dos dados e identificar desequilíbrios ou padrões nas classes\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize= (10,8))\n",
        "# Obtém as contagens de cada classe em 'y' e cria um gráfico de barras com cores diferentes para cada barra.\n",
        "\n",
        "y.value_counts().plot(ax=ax,\n",
        "                      kind=\"bar\",\n",
        "                      color=plt.cm.Paired(range(len(y.value_counts()))))\n",
        "\n",
        "# Exibe o gráfico.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SSp3uUYCaA9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine learning**\n",
        "\n",
        " Divisão dos dados em conjuntos de treinamento e teste utilizando a função"
      ],
      "metadata": {
        "id": "Ctk64pgsXoQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão dos dados em conjuntos de treinamento e teste utilizando a função train_test_split.\n",
        "# O conjunto de teste terá 30% dos dados, com semente aleatória 42\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "Kq4Y9ItCaUk9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das classes enable_halving_search_cv e HalvingGridSearchCV do módulo sklearn.experimental.\n",
        "# Estas classes permitem utilizar a técnica de busca em grade (Grid Search) com redução de amostras (Halving).\n",
        "\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV"
      ],
      "metadata": {
        "id": "rXximxyBbaRQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RANDOM FOREST**\n",
        "\n",
        "É um algoritmo de aprendizado de máquina que combina várias árvores de decisão usando amostragem por bootstrap e seleção aleatória de recursos. É eficaz em classificação e regressão"
      ],
      "metadata": {
        "id": "CdwJoQaCb0Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário 'p' com diferentes combinações de hiperparâmetros para a busca em grade.\n",
        "p = {\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "    'max_depth': [5, 7, 9],\n",
        "    'min_samples_split': [2, 3],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_samples': [0.8, 1],\n",
        "}\n",
        "\n",
        "# Instância do modelo Random Forest com estado aleatório 42.\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Aplicação da busca em grade ao modelo com validação cruzada (5 dobras).\n",
        "cv_rf = GridSearchCV(estimator=rf, param_grid=p, cv=5)\n",
        "\n",
        "# Treinamento do modelo com o conjunto de treinamento (X_train e y_train).\n",
        "cv_rf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "GAmhPSjEbwG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melhores hiperparâmetros encontrados pela busca em grade (Grid Search) para o modelo Random Forest.\n",
        "best_params = cv_rf.best_params_\n",
        "best_params"
      ],
      "metadata": {
        "id": "o_FuT8UUc8MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza a previsão do modelo treinado com os melhores hiperparâmetros no conjunto de teste (X_test).\n",
        "y_pred = cv_rf.predict(X_test)\n",
        "\n",
        "# Calcula a pontuação F1 usando as previsões e os rótulos verdadeiros do conjunto de teste (y_test),\n",
        "# considerando a média micro para calcular a pontuação F1.\n",
        "f1_score_micro_random = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "\n",
        "# A pontuação F1 micro é uma métrica de desempenho em tarefas de classificação.\n",
        "print(f'Pontuação F1 do modelo Random Forest: {f1_score_micro_random:.2f}')\n"
      ],
      "metadata": {
        "id": "6TPznsjbdHei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP**\n",
        "Multilayer Perceptron (MLP) é um tipo de rede neural artificial com várias camadas ocultas que utiliza algoritmos de retropropagação para ajustar os pesos e realizar aprendizado supervisionado. É amplamente usado em classificação, regressão e reconhecimento de padrões em dados complexos"
      ],
      "metadata": {
        "id": "gBDFQp4gdY1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário 'p' com diferentes hiperparâmetros para busca em grade.\n",
        "p = {\n",
        "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "    'alpha': [1],\n",
        "    'max_iter': [1000],\n",
        "}\n",
        "\n",
        "# Instância do classificador MLP com três camadas ocultas de 100 neurônios cada.\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100,))\n",
        "\n",
        "# Aplicação da busca em grade ao modelo MLP com validação cruzada (5 dobras).\n",
        "cv_mlp = GridSearchCV(estimator=mlp, param_grid=p, cv=5)\n",
        "\n",
        "# Treinamento do modelo MLP com o conjunto de treinamento (X_train e y_train).\n",
        "cv_mlp.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Ar8jo_QsdxDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melhores hiperparâmetros encontrados pela busca em grade (Grid Search) para o modelo Multilayer Perceptron (MLP).\n",
        "best_params_ = cv_mlp.best_params_\n",
        "best_params_"
      ],
      "metadata": {
        "id": "dCAI5qxndzhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza a previsão do modelo MLP treinado com os melhores hiperparâmetros no conjunto de teste (X_test).\n",
        "y_pred = cv_mlp.predict(X_test,)\n",
        "\n",
        "# Calcula a pontuação F1 usando as previsões feitas pelo modelo (y_pred) e os rótulos verdadeiros do conjunto de teste (y_test).\n",
        "# A média micro é utilizada para calcular a pontuação F1, que é uma métrica de desempenho em tarefas de classificação.\n",
        "f1_score_micro_MLP = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "\n",
        "# A pontuação F1 micro é uma métrica de desempenho em tarefas de classificação.\n",
        "print(f'Pontuação F1 do modelo MLP: {f1_score_micro_MLP:.2f}')\n"
      ],
      "metadata": {
        "id": "27rbv-VBeGT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVC**\n",
        "\n",
        "SVC (Support Vector Classification) é um algoritmo de aprendizado de máquina usado para problemas de classificação. Ele encontra um hiperplano ótimo para separar duas classes no espaço de características. É eficaz em problemas lineares e não lineares."
      ],
      "metadata": {
        "id": "hVtJD5T7efbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário 'p' com diferentes hiperparâmetros para busca em grade.\n",
        "\n",
        "p = {\n",
        "    'gamma': ['auto', 'scale'],\n",
        "    'C': [0.5, 1],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Instância do classificador SVC (Support Vector Classification).\n",
        "svc = SVC()\n",
        "\n",
        "# Aplicação da busca em grade ao modelo SVC com validação cruzada (5 dobras).\n",
        "cv_svc = GridSearchCV(estimator=svc, param_grid=p, cv=5)\n",
        "\n",
        "# Treinamento do modelo SVC com o conjunto de treinamento (X_train e y_train).\n",
        "cv_svc.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "3AwoF8Q-em1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melhores hiperparâmetros encontrados pela busca em grade (Grid Search) para o modelo Support Vector Classification (SVC).\n",
        "best_params_ = cv_svc.best_params_\n",
        "best_params_"
      ],
      "metadata": {
        "id": "K5FbzZH_ggc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza a previsão do modelo SVC treinado com os melhores hiperparâmetros no conjunto de teste (X_test).\n",
        "y_pred = cv_svc.predict(X_test)\n",
        "\n",
        "# Calcula a pontuação F1 usando as previsões feitas pelo modelo (y_pred) e os rótulos verdadeiros do conjunto de teste (y_test).\n",
        "# A média micro é utilizada para calcular a pontuação F1, que é uma métrica de desempenho em tarefas de classificação.\n",
        "f1_score_micro_svc = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "# A pontuação F1 micro é uma métrica de desempenho em tarefas de classificação.\n",
        "print(f'Pontuação F1 do modelo SVC: {f1_score_micro_svc:.2f}')"
      ],
      "metadata": {
        "id": "VCzQiCMZg7iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBClassifier**\n",
        "\n",
        "XGBClassifier é um algoritmo de aprendizado de máquina baseado em gradient boosting usado para classificação e regressão. Ele é eficiente, rápido e pode lidar com grandes conjuntos de dados"
      ],
      "metadata": {
        "id": "CPodRz6BhD-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário 'p' com diferentes hiperparâmetros para busca em grade.\n",
        "\n",
        "DEFAULT_RANDOM_STATE = 42\n",
        "\n",
        "p = {\n",
        "    'learning_rate': [0.01],\n",
        "    'n_estimators': [100],\n",
        "    'subsample': [0.8, 0.45],\n",
        "    'min_child_weight': [1],\n",
        "    'max_depth': [3, 4, 7],\n",
        "    'random_state': [DEFAULT_RANDOM_STATE],\n",
        "    'reg_lambda': [2],\n",
        "}\n",
        "\n",
        "# Instância do classificador XGBClassifier.\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Aplicação da busca em grade ao modelo XGBClassifier com validação cruzada (5 dobras).\n",
        "cv_xgb = GridSearchCV(estimator=xgb, param_grid=p, cv=5)\n",
        "\n",
        "# Treinamento do modelo XGBClassifier com o conjunto de treinamento (X_train e y_train).\n",
        "cv_xgb.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "dE8eP9UyhxYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melhores hiperparâmetros encontrados pela busca em grade (Grid Search) para o modelo XGBClassifier.\n",
        "\n",
        "best_params_ = cv_xgb.best_params_\n",
        "best_params_"
      ],
      "metadata": {
        "id": "EuBaV296p7ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza a previsão do modelo XGBClassifier treinado com os melhores hiperparâmetros no conjunto de teste (X_test).\n",
        "y_pred = cv_xgb.predict(X_test)\n",
        "\n",
        "# Calcula a pontuação F1 usando as previsões feitas pelo modelo (y_pred) e os rótulos verdadeiros do conjunto de teste (y_test).\n",
        "# A média micro é utilizada para calcular a pontuação F1, que é uma métrica de desempenho em tarefas de classificação.\n",
        "f1_score_micro_XGB = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "\n",
        "# A pontuação F1 micro é uma métrica de desempenho em tarefas de classificação.\n",
        "print(f'Pontuação F1 do modelo XGBClassifier: {f1_score_micro_XGB:.2f}')\n"
      ],
      "metadata": {
        "id": "gXrdgbKKqS5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritimo com melhor desempenho na classificação"
      ],
      "metadata": {
        "id": "fjxReQF5qjLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Pontuação F1 do modelo Random Forest: {f1_score_micro_random:.2f}')\n",
        "\n",
        "print(f'Pontuação F1 do modelo MLP: {f1_score_micro_MLP:.2f}')\n",
        "\n",
        "print(f'Pontuação F1 do modelo SVC: {f1_score_micro_svc:.2f}')\n",
        "\n",
        "print(f'Pontuação F1 do modelo XGBClassifier: {f1_score_micro_XGB:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "RO3UfK5yrQUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmo Random Forest\n",
        "selecionado, porque tem maior f1_score"
      ],
      "metadata": {
        "id": "XLh-1RDlqruE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instância do modelo RandomForestClassifier com os hiperparâmetros selecionados.\n",
        "rf = RandomForestClassifier(random_state=42,\n",
        "                            max_depth=9,\n",
        "                            max_samples=0.8,\n",
        "                            min_samples_leaf=1,\n",
        "                            min_samples_split=2,\n",
        "                            n_estimators=1000)\n",
        "\n"
      ],
      "metadata": {
        "id": "aUdQp7eVqiPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treina o modelo RandomForestClassifier com o conjunto de treinamento (X_train e y_train).\n",
        "rf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "FNBZHYt9sPrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime a dimensão do conjunto de dados de entrada (X).\n",
        "print(X.shape)\n",
        "\n",
        "# Imprime a dimensão do conjunto de rótulos (y).\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "id": "JSBd23llsX9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtém os nomes das colunas (características) do conjunto de dados de entrada (X).\n",
        "colnames = X.columns\n",
        "\n",
        "# Cria um DataFrame 'feature_importances' contendo as importâncias das características,\n",
        "# obtidas a partir do modelo RandomForestClassifier (rf), indexado pelos nomes das colunas.\n",
        "\n",
        "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
        "                                   index=colnames,\n",
        "                                   columns=['importance'])\n"
      ],
      "metadata": {
        "id": "-ryiC0A9sfnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria uma figura com o tamanho de 12x5 polegadas para o gráfico de barras.\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Cria um gráfico de barras utilizando o Seaborn (sns), onde o eixo x são os nomes das colunas (características)\n",
        "# e o eixo y representa as importâncias das características, obtidas do DataFrame 'feature_importances'.\n",
        "g = sns.barplot(x=colnames, y=feature_importances['importance'])\n",
        "\n",
        "# Rotaciona os rótulos do eixo x em 90 graus para melhor legibilidade.\n",
        "g.tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Exibe o gráfico de barras.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mxx3iSAKs9zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a classe FeatureImportances da biblioteca Yellowbrick, que permite visualizar as importâncias das características.\n",
        "from yellowbrick.features import FeatureImportances\n",
        "\n",
        "# Cria uma figura com o tamanho de 15x10 polegadas para a visualização.\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Instancia um modelo RandomForestClassifier.\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Cria um objeto FeatureImportances com o modelo RandomForestClassifier.\n",
        "viz = FeatureImportances(model)\n",
        "\n",
        "# Ajusta o objeto FeatureImportances aos dados de entrada (X) e rótulos (y) para calcular as importâncias das características.\n",
        "viz.fit(X, y)\n",
        "\n",
        "# Mostra o gráfico de importâncias das características.\n",
        "viz.show()\n"
      ],
      "metadata": {
        "id": "jhWOVZ3WtSYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import eli5\n",
        "eli5.show_weights(rf, feature_names = X_train.columns.tolist())"
      ],
      "metadata": {
        "id": "-B5NFOCc-Aga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a função show_prediction da biblioteca eli5\n",
        "from eli5 import show_prediction\n",
        "\n",
        "# Exibindo a explicação das previsões feitas pelo modelo de Random Forest (rf) para um exemplo específico (X_train.iloc[1])\n",
        "# feature_names é uma lista que contém os nomes das características (features) presentes no conjunto de treinamento (X_train)\n",
        "# show_feature_values=True indica que queremos mostrar os valores das características (features) na explicação\n",
        "\n",
        "show_prediction(rf, X_train.iloc[1], feature_names=X_train.columns.tolist(), show_feature_values=True)\n"
      ],
      "metadata": {
        "id": "yt94DaQn-Dyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo a previsão das classes ou valores usando o modelo de Random Forest (rf)\n",
        "y_pred = rf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Qe6ciVxO-GB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "metadata": {
        "id": "ePQe5CBk-IL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plot_confusion_matrix(rf, X_test, y_test, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CE1yNyTu-J1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(precision_score(y_test, y_pred, average='weighted'))\n",
        "print(recall_score(y_test, y_pred, average='weighted'))"
      ],
      "metadata": {
        "id": "223mNTn5-McJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrai as classes alvo (rótulos) do DataFrame 'df' e armazena na variável 'y'.\n",
        "y = df['classe']\n",
        "\n",
        "# Remove a coluna 'classe' do DataFrame 'df' e armazena o restante dos dados na variável 'X'.\n",
        "X = df.drop(columns=['classe'])\n"
      ],
      "metadata": {
        "id": "-2oK-F98-OmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['mean_mde'][X['mean_mde'] < 0] = 0\n",
        "X['q50_mde'][X['q50_mde'] < 0] = 0\n",
        "X['sd_mde'][X['sd_mde'] < 0] = 0"
      ],
      "metadata": {
        "id": "2dyDjWGv-SLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza a predição das classes utilizando o modelo Random Forest treinado 'rf' nos dados de entrada 'X'.\n",
        "class_df = rf.predict(X)\n"
      ],
      "metadata": {
        "id": "PvRcz3DX-UPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação de um DataFrame chamado df_pred a partir de um objeto chamado class_df\n",
        "df_pred = pd.DataFrame(class_df)\n"
      ],
      "metadata": {
        "id": "WYUAiecT-juO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca \"files\" do Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Salvando o DataFrame df_pred em um arquivo CSV chamado 'df_final.csv', sem incluir o índice\n",
        "df_pred.to_csv('df_final.csv', index=False)\n",
        "\n",
        "# Fazendo o download do arquivo 'df_final.csv' para o seu dispositivo local\n",
        "files.download('df_final.csv')\n"
      ],
      "metadata": {
        "id": "RB44VxDI-al6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparar Algoritimos de machine learning"
      ],
      "metadata": {
        "id": "i7z4u2QFjTLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados com as pontuações F1-Score para diferentes modelos de Machine Learning\n",
        "data = {'Random Forest': f1_score_micro_random,\n",
        "        'XGBClassifier': f1_score_micro_XGB,\n",
        "        'SVC': f1_score_micro_svc,\n",
        "        'MLP': f1_score_micro_MLP}\n",
        "\n",
        "# Lista dos modelos (chaves) e das pontuações F1-Score (valores)\n",
        "courses = list(data.keys())\n",
        "values = list(data.values())\n",
        "\n",
        "# Criando uma figura (gráfico) com tamanho 10x5\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Criando um gráfico de barras\n",
        "plt.bar(courses, values, width=0.4)\n",
        "\n",
        "# Definindo o rótulo do eixo Y\n",
        "plt.ylabel(\"F1-Score\")\n",
        "\n",
        "# Definindo o título do gráfico\n",
        "plt.title(\"Avaliação dos modelos de Machine Learning\")\n",
        "\n",
        "# Exibindo o gráfico\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "U2-2b9T5-fKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KbVSlhKGfp4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}